#!/usr/bin/env python3
"""
Execute v3 Execution Pack - Autonomous R&D Factory Cursor Agent

Purpose: Automatically execute v3 Execution Pack generated by GPT.
Parses markdown, performs edits, runs commands, validates outputs,
and generates execution report.

Usage:
    py tools/execute_v3_pack.py <v3_execution_pack.md>
"""

from __future__ import annotations

import os
import sys
import re
import json
import subprocess
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

# Bootstrap: Add project root to sys.path
_script_path = Path(__file__).resolve()
_project_root = _script_path.parent.parent
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))


def parse_v3_pack(md_path: Path) -> Dict[str, Any]:
    """Parse v3 Execution Pack markdown into structured data."""
    
    content = md_path.read_text(encoding="utf-8")
    
    # Extract Human Summary
    human_summary_match = re.search(r'# Human Summary\n(.*?)(?=\n# |$)', content, re.DOTALL)
    human_summary = human_summary_match.group(1).strip() if human_summary_match else ""
    
    # Extract Cursor Execution Prompt section
    execution_section_match = re.search(r'# Cursor Execution Prompt\n(.*?)(?=\n# Stop Triggers|$)', content, re.DOTALL)
    execution_section = execution_section_match.group(1) if execution_section_match else ""
    
    # Extract Stop Triggers JSON
    stop_triggers_match = re.search(r'```json\n(.*?)\n```', content, re.DOTALL)
    stop_triggers = {}
    if stop_triggers_match:
        try:
            stop_triggers = json.loads(stop_triggers_match.group(1))
        except json.JSONDecodeError:
            print("[WARN] Failed to parse Stop Triggers JSON")
    
    # Parse execution steps
    steps = []
    step_pattern = r'## Step \d+: ([^\n]+)\n(.*?)(?=\n## Step |\n## Final Verification|$)'
    for match in re.finditer(step_pattern, execution_section, re.DOTALL):
        step_title = match.group(1)
        step_content = match.group(2)
        
        # Extract file path
        file_match = re.search(r'\*\*File\*\*: `([^`]+)`', step_content)
        file_path = file_match.group(1) if file_match else None
        
        # Extract line numbers or function name
        line_match = re.search(r'\*\*Line\*\*: ([^\n]+)', step_content)
        lines = line_match.group(1).strip() if line_match else None
        
        # Extract action
        action_match = re.search(r'\*\*Action\*\*: ([^\n]+)', step_content)
        action = action_match.group(1).strip() if action_match else None
        
        # Extract command
        command_match = re.search(r'```bash\n(.*?)\n```', step_content, re.DOTALL)
        command = command_match.group(1).strip() if command_match else None
        
        # Extract expected outputs
        expected_match = re.search(r'\*\*Expected Output\*\*:\n(.*?)(?=\*\*Verification|$)', step_content, re.DOTALL)
        expected_outputs = expected_match.group(1).strip() if expected_match else None
        
        # Extract verification
        verification_match = re.search(r'\*\*Verification\*\*:\n```bash\n(.*?)\n```', step_content, re.DOTALL)
        verification = verification_match.group(1).strip() if verification_match else None
        
        steps.append({
            "title": step_title,
            "file": file_path,
            "lines": lines,
            "action": action,
            "command": command,
            "expected_outputs": expected_outputs,
            "verification": verification,
        })
    
    # Extract Final Verification
    final_verification_match = re.search(r'## Final Verification\n(.*?)(?=\n# Stop Triggers|$)', execution_section, re.DOTALL)
    final_verification = final_verification_match.group(1).strip() if final_verification_match else ""
    
    # Extract Prerequisites
    prerequisites_match = re.search(r'## Prerequisites\n(.*?)(?=\n## Step |$)', execution_section, re.DOTALL)
    prerequisites = prerequisites_match.group(1).strip() if prerequisites_match else ""
    
    # Extract Scope Lock (if present)
    scope_lock_match = re.search(r'## Scope Lock\n(.*?)(?=\n## |$)', execution_section, re.DOTALL)
    scope_lock = scope_lock_match.group(1).strip() if scope_lock_match else None
    
    # Extract Exact Edits (if present)
    exact_edits_match = re.search(r'## Exact Edits\n(.*?)(?=\n## |$)', execution_section, re.DOTALL)
    exact_edits = exact_edits_match.group(1).strip() if exact_edits_match else None
    
    return {
        "human_summary": human_summary,
        "prerequisites": prerequisites,
        "scope_lock": scope_lock,
        "exact_edits": exact_edits,
        "steps": steps,
        "final_verification": final_verification,
        "stop_triggers": stop_triggers,
    }


def check_scope_lock(pack: Dict[str, Any], modified_files: List[str]) -> Tuple[bool, Optional[str]]:
    """Check if any modifications violate scope lock."""
    
    if not pack.get("scope_lock"):
        return True, None
    
    scope_lock = pack["scope_lock"]
    
    # Parse scope lock rules (simple pattern matching for now)
    # Example: "Only modify files in core/policy/, docs/policies/"
    allowed_patterns = []
    disallowed_patterns = []
    
    for line in scope_lock.split("\n"):
        line = line.strip()
        if "only" in line.lower() or "allow" in line.lower():
            # Extract paths
            path_matches = re.findall(r'`([^`]+)`', line)
            allowed_patterns.extend(path_matches)
        elif "not" in line.lower() or "forbid" in line.lower() or "prohibit" in line.lower():
            path_matches = re.findall(r'`([^`]+)`', line)
            disallowed_patterns.extend(path_matches)
    
    # Check each modified file
    for file_path in modified_files:
        # Check disallowed patterns
        for pattern in disallowed_patterns:
            if pattern in file_path or file_path.startswith(pattern):
                return False, f"File {file_path} violates scope lock (disallowed: {pattern})"
        
        # Check allowed patterns (if any specified)
        if allowed_patterns:
            allowed = any(pattern in file_path or file_path.startswith(pattern) for pattern in allowed_patterns)
            if not allowed:
                return False, f"File {file_path} violates scope lock (not in allowed patterns: {allowed_patterns})"
    
    return True, None


def apply_file_edit(file_path: str, lines: Optional[str], action: Optional[str], exact_edits: Optional[str]) -> bool:
    """Apply file edit based on step instructions."""
    
    full_path = Path(_project_root) / file_path
    if not full_path.exists():
        print(f"[ERROR] File not found: {file_path}")
        return False
    
    # If exact_edits is provided, use it
    if exact_edits:
        # Simple implementation: exact_edits contains the full file replacement or diff
        # For now, we'll log and skip (should be implemented based on format)
        print(f"[INFO] Exact edits specified for {file_path}, but auto-editing requires manual review")
        return False
    
    # If action is specified, try to interpret it
    if action and lines:
        # Simple string replacement for now
        content = full_path.read_text(encoding="utf-8")
        original_content = content
        
        # Basic patterns
        if "Change" in action and "to" in action:
            # Extract old and new values
            old_match = re.search(r"Change `([^`]+)` to `([^`]+)`", action)
            if old_match:
                old_val = old_match.group(1)
                new_val = old_match.group(2)
                content = content.replace(old_val, new_val)
        
        if content != original_content:
            full_path.write_text(content, encoding="utf-8")
            print(f"[OK] Applied edit to {file_path}")
            return True
        else:
            print(f"[WARN] No changes applied to {file_path}")
            return False
    
    print(f"[INFO] Skipping file edit for {file_path} (requires manual intervention)")
    return False


def run_command(command: str, cwd: Optional[Path] = None) -> Tuple[int, str, str]:
    """Run shell command and return exit code, stdout, stderr."""
    
    if cwd is None:
        cwd = _project_root
    
    # Handle multi-line commands
    commands = [cmd.strip() for cmd in command.split("\n") if cmd.strip()]
    
    stdout_parts = []
    stderr_parts = []
    exit_code = 0
    
    for cmd in commands:
        try:
            result = subprocess.run(
                cmd,
                shell=True,
                cwd=str(cwd),
                capture_output=True,
                text=True,
                encoding="utf-8",
            )
            exit_code = result.returncode
            stdout_parts.append(result.stdout)
            stderr_parts.append(result.stderr)
            
            if exit_code != 0:
                print(f"[ERROR] Command failed: {cmd}")
                print(f"  Exit code: {exit_code}")
                print(f"  Stderr: {result.stderr}")
                break
        except Exception as e:
            print(f"[ERROR] Exception running command: {cmd}")
            print(f"  Error: {e}")
            exit_code = 1
            break
    
    return exit_code, "\n".join(stdout_parts), "\n".join(stderr_parts)


def verify_expected_output(expected_outputs: str) -> Tuple[bool, List[str]]:
    """Verify that expected outputs exist."""
    
    if not expected_outputs:
        return True, []
    
    issues = []
    
    # Check for file existence
    file_pattern = r'- File: `([^`]+)`'
    for match in re.finditer(file_pattern, expected_outputs):
        file_path = match.group(1)
        full_path = Path(_project_root) / file_path
        if not full_path.exists():
            issues.append(f"Expected file not found: {file_path}")
    
    # Check for directory existence
    dir_pattern = r'- Directory `([^`]+)`'
    for match in re.finditer(dir_pattern, expected_outputs):
        dir_path = match.group(1)
        full_path = Path(_project_root) / dir_path
        if not full_path.exists() or not full_path.is_dir():
            issues.append(f"Expected directory not found: {dir_path}")
    
    # Check for JSON field (simple check)
    json_field_pattern = r'- JSON field: `([^`]+)` should (?:contain|equal|be)'
    for match in re.finditer(json_field_pattern, expected_outputs):
        field_spec = match.group(1)
        # Extract file path from context if available
        # For now, just note that JSON verification needs manual check
        issues.append(f"JSON field verification needed: {field_spec}")
    
    return len(issues) == 0, issues


def get_run_id() -> str:
    """Get current RUN_ID from environment or generate one."""
    run_id = os.environ.get("RUN_ID", "")
    if not run_id:
        now_kst = datetime.utcnow().replace(tzinfo=None) + datetime.timedelta(hours=9)
        run_id = now_kst.strftime("%Y%m%d_%H%M%S")
    return run_id


def create_branch(run_id: str) -> str:
    """Create new git branch for this execution."""
    branch_name = f"auto/exec-{run_id}"
    
    # Check if branch exists
    result = subprocess.run(
        ["git", "branch", "--show-current"],
        cwd=str(_project_root),
        capture_output=True,
        text=True,
    )
    current_branch = result.stdout.strip()
    
    if current_branch != branch_name:
        # Create and checkout new branch
        subprocess.run(
            ["git", "checkout", "-b", branch_name],
            cwd=str(_project_root),
            check=False,
        )
        print(f"[OK] Created and checked out branch: {branch_name}")
    
    return branch_name


def commit_changes(run_id: str, modified_files: List[str]) -> Optional[str]:
    """Commit changes with standard message."""
    
    if not modified_files:
        print("[INFO] No files modified, skipping commit")
        return None
    
    # Stage all modified files
    for file_path in modified_files:
        subprocess.run(
            ["git", "add", file_path],
            cwd=str(_project_root),
            check=False,
        )
    
    # Commit
    commit_msg = f"auto(exec): apply v3 execution pack [{run_id}]"
    result = subprocess.run(
        ["git", "commit", "-m", commit_msg],
        cwd=str(_project_root),
        capture_output=True,
        text=True,
    )
    
    if result.returncode == 0:
        # Get commit SHA
        sha_result = subprocess.run(
            ["git", "rev-parse", "HEAD"],
            cwd=str(_project_root),
            capture_output=True,
            text=True,
        )
        commit_sha = sha_result.stdout.strip()
        print(f"[OK] Committed changes: {commit_sha}")
        return commit_sha
    else:
        print(f"[ERROR] Commit failed: {result.stderr}")
        return None


def generate_execution_report(
    pack: Dict[str, Any],
    run_id: str,
    modified_files: List[str],
    commands_executed: List[str],
    verification_results: List[Tuple[bool, List[str]]],
    commit_sha: Optional[str],
    pr_url: Optional[str],
) -> Path:
    """Generate execution report markdown."""
    
    report_path = Path(_project_root) / "execution_report.md"
    
    # Determine overall result
    all_verified = all(result[0] for result in verification_results)
    evidence_status = "PASS" if all_verified else "FAIL"
    
    report = f"""# Execution Report

## RUN_ID
{run_id}

## Human Summary
{pack.get('human_summary', 'N/A')}

## Modified Files
"""
    
    for file_path in modified_files:
        report += f"- {file_path}\n"
    
    report += f"""
## Commands Executed
"""
    
    for i, cmd in enumerate(commands_executed, 1):
        report += f"### Command {i}\n```bash\n{cmd}\n```\n\n"
    
    report += f"""
## Evidence Validation Result
{evidence_status}

"""
    
    # Add verification details
    for i, (success, issues) in enumerate(verification_results, 1):
        report += f"### Verification {i}\n"
        report += f"Status: {'PASS' if success else 'FAIL'}\n"
        if issues:
            report += "Issues:\n"
            for issue in issues:
                report += f"- {issue}\n"
        report += "\n"
    
    report += f"""## Commit SHA
{commit_sha if commit_sha else 'N/A'}

## PR URL
{pr_url if pr_url else 'N/A'}

## Generated At
{datetime.now().isoformat()}
"""
    
    report_path.write_text(report, encoding="utf-8")
    print(f"[OK] Generated execution report: {report_path}")
    
    return report_path


def main():
    parser = argparse.ArgumentParser(
        description="Execute v3 Execution Pack"
    )
    parser.add_argument(
        "execution_pack",
        type=str,
        help="Path to v3 Execution Pack markdown file",
    )
    args = parser.parse_args()
    
    pack_path = Path(args.execution_pack)
    if not pack_path.exists():
        print(f"[ERROR] Execution pack not found: {pack_path}")
        sys.exit(1)
    
    if not pack_path.is_absolute():
        pack_path = _project_root / pack_path
    
    print("=" * 80)
    print("Execute v3 Execution Pack")
    print("=" * 80)
    print(f"Pack: {pack_path}")
    print()
    
    # Parse execution pack
    print("[1/6] Parsing execution pack...")
    try:
        pack = parse_v3_pack(pack_path)
        print(f"[OK] Parsed {len(pack['steps'])} steps")
    except Exception as e:
        print(f"[ERROR] Failed to parse execution pack: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # Get RUN_ID
    run_id = get_run_id()
    print(f"[OK] RUN_ID: {run_id}")
    print()
    
    # Create branch
    print("[2/6] Creating git branch...")
    branch_name = create_branch(run_id)
    print()
    
    # Check prerequisites
    if pack.get("prerequisites"):
        print("[3/6] Checking prerequisites...")
        print(pack["prerequisites"])
        # Prerequisites are informational for now
        print("[OK] Prerequisites noted")
        print()
    
    # Execute steps
    print("[4/6] Executing steps...")
    modified_files = []
    commands_executed = []
    verification_results = []
    
    for i, step in enumerate(pack["steps"], 1):
        print(f"  Step {i}: {step['title']}")
        
        # Apply file edit if needed
        if step.get("file") and step.get("action"):
            if apply_file_edit(
                step["file"],
                step.get("lines"),
                step.get("action"),
                pack.get("exact_edits"),
            ):
                if step["file"] not in modified_files:
                    modified_files.append(step["file"])
        
        # Run command if specified
        if step.get("command"):
            exit_code, stdout, stderr = run_command(step["command"])
            commands_executed.append(step["command"])
            if exit_code != 0:
                print(f"[ERROR] Step {i} command failed")
                sys.exit(1)
        
        # Verify expected outputs
        if step.get("expected_outputs"):
            success, issues = verify_expected_output(step["expected_outputs"])
            verification_results.append((success, issues))
            if not success:
                print(f"[WARN] Step {i} verification failed: {issues}")
        
        # Run verification command if specified
        if step.get("verification"):
            exit_code, stdout, stderr = run_command(step["verification"])
            if exit_code != 0:
                print(f"[WARN] Step {i} verification command failed")
                verification_results.append((False, [f"Verification command failed: {stderr}"]))
            else:
                verification_results.append((True, []))
    
    print()
    
    # Check scope lock
    print("[5/6] Checking scope lock...")
    scope_valid, scope_error = check_scope_lock(pack, modified_files)
    if not scope_valid:
        print(f"[ERROR] Scope lock violation: {scope_error}")
        sys.exit(1)
    print("[OK] Scope lock check passed")
    print()
    
    # Final verification
    if pack.get("final_verification"):
        print("Final verification...")
        exit_code, stdout, stderr = run_command(pack["final_verification"])
        if exit_code != 0:
            print(f"[WARN] Final verification failed")
        print()
    
    # Commit changes
    print("[6/6] Committing changes...")
    commit_sha = commit_changes(run_id, modified_files)
    print()
    
    # Generate report
    print("Generating execution report...")
    report_path = generate_execution_report(
        pack,
        run_id,
        modified_files,
        commands_executed,
        verification_results,
        commit_sha,
        pr_url=None,  # PR URL would need GitHub API integration
    )
    print()
    
    print("=" * 80)
    print("[OK] Execution complete!")
    print(f"Report: {report_path}")
    print("=" * 80)


if __name__ == "__main__":
    main()
